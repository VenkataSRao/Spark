Concepts of Spark:
====================================
--- Spark Application consits of driver program, that launches parallel oerations on a cluster..
--- Driver program contains applications main function and defines distributed dataset and applies operates to them.
          Operations --> (Transformations & actions )
          
--- Driver Programs access path through SparkContext object, which connects computing cluster..
--- Once SparkContext is available, it will be used to build RDD's
--- To run operations in RDD, Driver program manages a  number of executors on the workers.
--- Standalone applications in spark can be developed in scala/java/python.. Spark and its related libraries must be included in application to use API's
--- Maven is popular package management tool for java applications, which allows to link libraries in public repository
--- For applications in scala SBT tool is used and eclipse IDE is for development


Spark Shell:
=============================

--- Spark comes with interactive shell which enables adhoc data analysis.
--- Shell runs in local or in distributted mode
--- Spark provides both python and scala shell


