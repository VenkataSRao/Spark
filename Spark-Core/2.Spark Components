Compponents of Spark are
  - Spark Core
  - Spark Streaming
  - MLLib
  - Graphix
  - Spark SQL
  
SparkCore:
==========

  ---  It contains basic functionality includes components for task scheduling, memory management, fault recovery , Interactivity with storage system etc.,
  ---  it is home to the API that defines RDD's ( Resilient Distributed Dataset ) - Spark's main programming abstraction.
  ---  RDD is collection of items distributed across many nodes that can be computed in parallel
  ---  RDD contains partitions of data . ex: In case of HDFS, the blocks are nothing but partitions of RDD
  
  
SparkStreaming:
==============

--- This is Spark Component that enables processing of real time data.. ex for stream data is events generated by sensors and logs generated by websites
--- Streaming API closely matches Spark's core API
--- It allows to run sql queries on top of streaming data and machine learning algorithms for MLLib

MLLib:
=======

--- It provides multiple types of algorithms which includes classification, regression, recommendation as well as supporting functionalities such as model evaluation and data import
--- All algorithms scale out across cluster ( Have distributed implementation )

Graphix:
=========

--- It is library for manipulating graphs and perform graph-parallel computation Ex: Socail networking sites
--- Graphix also extends Spark's API and allows us to create graphs with vertices and edges..


SparkSQL:
========

--- This package to work with strcuted data
--- It allows querying data via sql, as well as apache hive variant of sql
--- It supports many sources of data including Hive tables, PARQUET and JSON
--- SparkSQL allows to intermix sql queries with programatic data manipulation supported by RDD's

SPARK runs on Hadoop YARN, Apache mesos and spark's own cluster manager called standalone scheduler...
  
